
---

# 📘 Creating Highly Available Kubernetes Clusters using `kubeadm`

Kubernetes clusters can be made highly available (HA) using `kubeadm` with **two main approaches**:

---

## 🧱 1. **Stacked Control Plane Nodes**
- **etcd and control plane** are hosted on the **same nodes**.
- **Requires fewer machines** (cost-efficient).
- Easier to manage.
- Less separation of concerns.

> Example: You have 3 servers. Each one runs kube-apiserver, controller-manager, scheduler, and etcd together.

---

## 🏗️ 2. **External etcd Cluster**
- **etcd runs separately** from control plane nodes.
- **More machines required**, but offers better fault isolation.
- Preferred for **larger, more secure clusters**.

> Example: 3 nodes for etcd only, and 3+ nodes for control plane.

---

### ❗ Important Notes
- Choose topology (Stacked or External etcd) based on your app needs and infra capabilities.
- These setups **do not support cloud load balancers or dynamic volumes**.
- For cloud setups, use cloud-native solutions (e.g., managed Kubernetes).

---

## ✅ Prerequisites for Both Topologies

### 🖥️ Machines Needed:
- **3 or more control plane nodes**
- **3 or more worker nodes**
- **Odd number of etcd members** (for quorum) — applies to external etcd.
- All machines must:
  - Meet `kubeadm`'s requirements.
  - Have container runtime installed (e.g., containerd or Docker).
  - Have full network connectivity (private/public).
  - Have SSH and `sudo` access.
  - Have `kubeadm` and `kubelet` installed.

> 📌 Example: 3 control plane + 3 worker + 3 etcd nodes = 9 machines total.

---

## 📦 Container Images
- All machines must be able to **pull images** from `registry.k8s.io`.
- If hosts have **no internet access**, pre-load images **manually**.

---

## 🧰 CLI Tools
- Install `kubectl` on your **PC** and **each control plane node**.
- Helps with cluster troubleshooting.

---

## ⚖️ Load Balancer Setup

- Create a **load balancer for kube-apiserver**.
- Must:
  - Forward **TCP** traffic to port `6443`.
  - Communicate with **all control plane nodes**.
  - Use a **DNS name**, not an IP (especially in cloud).

> Example: `api.cluster.example.com:6443` forwards to all control planes.

### 🔍 Test Load Balancer Connectivity
```bash
nc -zv -w 2 <LOAD_BALANCER_IP> 6443
```
- **"Connection refused"** is OK (API server not ready).
- **"Timeout"** means there's a problem — fix LB settings.

---

## 🚀 Stacked Control Plane Setup

### Step 1: Initialize First Control Plane Node
```bash
sudo kubeadm init --control-plane-endpoint "LB_DNS:6443" --upload-certs
```
- Use `--upload-certs` to share TLS certs with other control plane nodes.
- Use `--pod-network-cidr=10.244.0.0/16` if your CNI needs pod CIDR.

> 📝 Keep the output `kubeadm join` command safe – needed for joining other nodes.

---

### Step 2: Join Other Control Plane Nodes
```bash
sudo kubeadm join <LB_IP>:6443 \
  --token <TOKEN> \
  --discovery-token-ca-cert-hash sha256:<HASH> \
  --control-plane \
  --certificate-key <CERT_KEY>
```
- Can join multiple nodes **in parallel**.
- `--control-plane` tells `kubeadm` to add a new control plane.
- `--certificate-key` decrypts certificates.

> ⚠️ Certificate key is sensitive. Keep it secret. It expires after **2 hours**.

---

### Step 3: Join Worker Nodes
```bash
sudo kubeadm join <LB_IP>:6443 \
  --token <TOKEN> \
  --discovery-token-ca-cert-hash sha256:<HASH>
```

---

### Step 4: Install CNI (Container Network Interface)
- Choose a plugin (e.g., Flannel, Calico, Weave).
- Must match your `--pod-network-cidr` if set.

> Example (for Flannel):
```bash
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```

---

## 🛠️ Monitor Cluster Components
```bash
kubectl get pod -n kube-system -w
```
- This helps you **watch control plane pods** start up correctly.

---

## 🌐 External etcd Setup

### Step 1: Set Up etcd Cluster
- Follow etcd docs to set up 3 or more etcd nodes.
- Copy certs from one etcd node to the **first control plane**:

```bash
scp /etc/kubernetes/pki/etcd/ca.crt <CONTROL_PLANE_IP>:
scp /etc/kubernetes/pki/apiserver-etcd-client.crt <CONTROL_PLANE_IP>:
scp /etc/kubernetes/pki/apiserver-etcd-client.key <CONTROL_PLANE_IP>:
```

---

### Step 2: Create kubeadm-config.yaml
```yaml
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
kubernetesVersion: stable
controlPlaneEndpoint: "LB_DNS:6443"
etcd:
  external:
    endpoints:
      - https://10.0.0.1:2379
      - https://10.0.0.2:2379
      - https://10.0.0.3:2379
    caFile: /etc/kubernetes/pki/etcd/ca.crt
    certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
    keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key
```

> 📝 Replace etcd IPs and load balancer DNS as needed.

---

## 📚 Extra References
- [Kubeadm Upgrade Guide](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-upgrade/)
- [Load Balancer Options](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/#options-for-software-load-balancing)
- [kubeadm GitHub Issues](https://github.com/kubernetes/kubeadm/issues)

---

## 🧠 Exam Tips - Key Points to Remember

| Concept                          | Stacked etcd            | External etcd              |
|----------------------------------|--------------------------|----------------------------|
| etcd location                   | Co-located               | Separate machines          |
| Infra required                  | Less                     | More                       |
| Best for                        | Simpler, dev/test        | Prod, scalable environments |
| Cert sharing method            | `--upload-certs`         | Manual or custom           |
| Load balancer requirement      | Yes                      | Yes                        |
| etcd quorum importance         | Must use odd number      | Must use odd number        |

